import requests
import pandas as pd
from bs4 import BeautifulSoup
from sqlalchemy import create_engine
import os

# âœ… 1. æ•°æ®åº“è¿æ¥
db_url = 'mysql+pymysql://root:root@localhost:3306/covid_data'
engine = create_engine(db_url)

# âœ… 2. è®¾ç½®æœˆä»½ï¼ˆç”¨äºç­›é€‰ï¼‰
target_month = '2022.12'

# âœ… 3. è·å– GitHub releases é¡µä¸­æ‰€æœ‰åŒ…å« target_month çš„ç‰ˆæœ¬
def get_versions_by_month(month: str, max_pages=64):#æŸ¥æ‰¾é¡µæ•°æ§åˆ¶ï¼Œ2022å¹´12æœˆæ•°æ®å¤§æ¦‚åœ¨61-64é¡µä¸­é—´
    versions = set()
    headers = {"User-Agent": "Mozilla/5.0"}

    for page in range(61, max_pages + 1):
        url = f"https://github.com/BlankerL/DXY-COVID-19-Data/releases?page={page}"
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, 'html.parser')
        links = soup.find_all('a', class_='Link--primary')
        print(f"ğŸ“„ ç¬¬ {page} é¡µæŠ“åˆ° {len(links)} ä¸ªç‰ˆæœ¬å€™é€‰ï¼š")
        for link in links:
            version = link.text.strip()
            print("ğŸ” ç‰ˆæœ¬å€™é€‰ =", version)
            if version.startswith(month):
                versions.add(version)

    return sorted(versions)

# âœ… 4. å¤„ç†æ¯ä¸ªç‰ˆæœ¬çš„ DXYArea.csv
def import_dxyarea(version: str):
    url = f"https://github.com/BlankerL/DXY-COVID-19-Data/releases/download/{version}/DXYArea.csv"
    print(f"\nğŸ“¥ æ­£åœ¨å¯¼å…¥ç‰ˆæœ¬ï¼š{version}")
    try:
        df = pd.read_csv(url, encoding='utf-8')
        df = df[df['countryName'] == 'ä¸­å›½'].copy()
        df.fillna('', inplace=True)
        df['updateTime'] = pd.to_datetime(df['updateTime'])

        # location_info
        df_location = df[[
            'provinceName', 'provinceEnglishName', 'province_zipCode',
            'cityName', 'cityEnglishName', 'city_zipCode',
            'countryName', 'countryEnglishName'
        ]].drop_duplicates()
        df_location.columns = [
            'province_name', 'province_english_name', 'province_zip_code',
            'city_name', 'city_english_name', 'city_zip_code',
            'country_name', 'country_english_name'
        ]
        df_location.to_sql('location_info', con=engine, if_exists='replace', index=False)

        # province_stat
        df_province = df[[
            'provinceName', 'province_confirmedCount', 'province_suspectedCount',
            'province_curedCount', 'province_deadCount', 'updateTime'
        ]].drop_duplicates(subset='provinceName')
        df_province.columns = [
            'province_name', 'confirmed_count', 'suspected_count',
            'cured_count', 'dead_count', 'update_time'
        ]
        df_province.to_sql('province_stat', con=engine, if_exists='replace', index=False)

        # city_stat
        df_city = df[[
            'provinceName', 'cityName', 'city_confirmedCount', 'city_suspectedCount',
            'city_curedCount', 'city_deadCount', 'updateTime'
        ]]
        df_city = df_city[df_city['cityName'] != '']
        df_city.columns = [
            'province_name', 'city_name', 'confirmed_count',
            'suspected_count', 'cured_count', 'dead_count', 'update_time'
        ]
        df_city.to_sql('city_stat', con=engine, if_exists='replace', index=False)

        print(f"âœ… å¯¼å…¥å®Œæˆï¼š{version}")
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥ {version}: {e}")

# âœ… 5. ä¸»æ‰§è¡Œ
if __name__ == '__main__':
    versions = get_versions_by_month(target_month)
    if not versions:
        print(f"â— æœªæ‰¾åˆ° {target_month} çš„ç‰ˆæœ¬")
    else:
        print(f"ğŸ“Œ å…±æ‰¾åˆ° {len(versions)} ä¸ªç‰ˆæœ¬ï¼š{versions}")
        for v in versions:
            import_dxyarea(v)
